"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from baseten.types import BaseModel, Nullable, OptionalNullable, UNSET, UNSET_SENTINEL
from pydantic import model_serializer
from typing import List, Optional, Union
from typing_extensions import NotRequired, TypeAliasType, TypedDict


class ThreeTypedDict(TypedDict):
    audio_bytes: str


class Three(BaseModel):
    audio_bytes: str


class TwoTypedDict(TypedDict):
    audio_b64: str


class Two(BaseModel):
    audio_b64: str


class OneTypedDict(TypedDict):
    url: str


class One(BaseModel):
    url: str


AudioTypedDict = TypeAliasType(
    "AudioTypedDict", Union[OneTypedDict, TwoTypedDict, ThreeTypedDict]
)
r"""Audio input options. Provide one of the following: - url: URL of the audio file. - audio_b64: Base64-encoded audio content. - audio_bytes: Raw audio bytes.

"""


Audio = TypeAliasType("Audio", Union[One, Two, Three])
r"""Audio input options. Provide one of the following: - url: URL of the audio file. - audio_b64: Base64-encoded audio content. - audio_bytes: Raw audio bytes.

"""


class WhisperParamsTypedDict(TypedDict):
    r"""Parameters for controlling Whisper’s behavior."""

    prompt: NotRequired[str]
    r"""Optional transcription prompt."""
    audio_language: NotRequired[str]
    r"""Language of the input audio. Set to \"auto\" for automatic detection.

    """
    language_detection_only: NotRequired[bool]
    r"""If true, only return the automatic language detection result without transcribing.

    """
    use_dynamic_preprocessing: NotRequired[bool]
    r"""Enables dynamic range compression to process audio with variable loudness.

    """


class WhisperParams(BaseModel):
    r"""Parameters for controlling Whisper’s behavior."""

    prompt: Optional[str] = None
    r"""Optional transcription prompt."""

    audio_language: Optional[str] = "en"
    r"""Language of the input audio. Set to \"auto\" for automatic detection.

    """

    language_detection_only: Optional[bool] = False
    r"""If true, only return the automatic language detection result without transcribing.

    """

    use_dynamic_preprocessing: Optional[bool] = False
    r"""Enables dynamic range compression to process audio with variable loudness.

    """


class AsrOptionsTypedDict(TypedDict):
    r"""Advanced settings for the ASR process."""

    beam_size: NotRequired[int]
    r"""Beam search size for decoding. Supported up to 5."""
    length_penalty: NotRequired[float]
    r"""Length penalty applied to ASR output. Only applicable when beam_size > 1.

    """


class AsrOptions(BaseModel):
    r"""Advanced settings for the ASR process."""

    beam_size: Optional[int] = 1
    r"""Beam search size for decoding. Supported up to 5."""

    length_penalty: Optional[float] = 2
    r"""Length penalty applied to ASR output. Only applicable when beam_size > 1.

    """


class WhisperInputTypedDict(TypedDict):
    r"""Object containing audio and related parameters."""

    audio: AudioTypedDict
    r"""Audio input options. Provide one of the following: - url: URL of the audio file. - audio_b64: Base64-encoded audio content. - audio_bytes: Raw audio bytes.

    """
    whisper_params: NotRequired[WhisperParamsTypedDict]
    r"""Parameters for controlling Whisper’s behavior."""
    asr_options: NotRequired[AsrOptionsTypedDict]
    r"""Advanced settings for the ASR process."""


class WhisperInput(BaseModel):
    r"""Object containing audio and related parameters."""

    audio: Audio
    r"""Audio input options. Provide one of the following: - url: URL of the audio file. - audio_b64: Base64-encoded audio content. - audio_bytes: Raw audio bytes.

    """

    whisper_params: Optional[WhisperParams] = None
    r"""Parameters for controlling Whisper’s behavior."""

    asr_options: Optional[AsrOptions] = None
    r"""Advanced settings for the ASR process."""


class TranscribeAudioRequestBodyTypedDict(TypedDict):
    r"""Payload containing the audio input and transcription parameters."""

    whisper_input: WhisperInputTypedDict
    r"""Object containing audio and related parameters."""


class TranscribeAudioRequestBody(BaseModel):
    r"""Payload containing the audio input and transcription parameters."""

    whisper_input: WhisperInput
    r"""Object containing audio and related parameters."""


class TranscribeAudioAudiosResponseBodyTypedDict(TypedDict):
    r"""Unexpected error response."""

    error: NotRequired[str]
    r"""Error message."""


class TranscribeAudioAudiosResponseBody(BaseModel):
    r"""Unexpected error response."""

    error: Optional[str] = None
    r"""Error message."""


class SegmentsTypedDict(TypedDict):
    text: NotRequired[str]
    r"""Transcribed text."""
    log_prob: NotRequired[float]
    r"""Log probability of the transcription."""
    start_time: NotRequired[float]
    r"""Start time (in seconds) of the segment."""
    end_time: NotRequired[float]
    r"""End time (in seconds) of the segment."""


class Segments(BaseModel):
    text: Optional[str] = None
    r"""Transcribed text."""

    log_prob: Optional[float] = None
    r"""Log probability of the transcription."""

    start_time: Optional[float] = None
    r"""Start time (in seconds) of the segment."""

    end_time: Optional[float] = None
    r"""End time (in seconds) of the segment."""


class TranscribeAudioResponseBodyTypedDict(TypedDict):
    r"""Successful transcription response."""

    language_code: NotRequired[str]
    r"""Detected language code."""
    language_prob: NotRequired[Nullable[float]]
    r"""Confidence score for language detection."""
    segments: NotRequired[List[SegmentsTypedDict]]
    r"""List of transcribed segments."""


class TranscribeAudioResponseBody(BaseModel):
    r"""Successful transcription response."""

    language_code: Optional[str] = None
    r"""Detected language code."""

    language_prob: OptionalNullable[float] = UNSET
    r"""Confidence score for language detection."""

    segments: Optional[List[Segments]] = None
    r"""List of transcribed segments."""

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = ["language_code", "language_prob", "segments"]
        nullable_fields = ["language_prob"]
        null_default_fields = []

        serialized = handler(self)

        m = {}

        for n, f in self.model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)

            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )  # pylint: disable=no-member

            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                not k in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val

        return m


TranscribeAudioResponseTypedDict = TypeAliasType(
    "TranscribeAudioResponseTypedDict",
    Union[
        TranscribeAudioAudiosResponseBodyTypedDict, TranscribeAudioResponseBodyTypedDict
    ],
)


TranscribeAudioResponse = TypeAliasType(
    "TranscribeAudioResponse",
    Union[TranscribeAudioAudiosResponseBody, TranscribeAudioResponseBody],
)
